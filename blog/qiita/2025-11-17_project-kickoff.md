# 【育児エンジニア】育休3ヶ月でAI株式取引システム作ってみる - プロジェクト始動編

## TL;DR

- 育児休暇中の3ヶ月で、AIによる米国株式ニュース分析システムを構築するプロジェクトを開始
- AWS Lambda + Bedrock (Claude Haiku)でサーバーレス自動取引システムを実装予定
- 予算5万円、週1回30分のメンテナンスで運用できる設計を目指す

---

## はじめに

こんにちは、シュンペイです。

現在、育児休暇中のエンジニアです。子供と過ごす時間は最高ですが、「このままだとスキルが錆びつく...」という焦りもありました。

そこで、育児の合間に3ヶ月で**AIによる株式ニュース分析システム**を作ることにしました。

### この記事で得られること

- 育児と両立できる個人開発プロジェクトの設計思想
- AI（Claude）を使った金融ニュース分析の全体像
- AWSサーバーレスで24/7稼働する自動取引システムの構成
- 限られた予算・時間でプロジェクトを進める方法

---

## プロジェクト概要

### 何を作るのか？

**AIが米国株式ニュースを分析し、自動で取引判断を行うシステム**です。

具体的には：
- ニュース発生時、株価急変動時、経済指標発表時にトリガー起動
- AWS Bedrock（Claude 3 Haiku）がニュースと市場データを分析
- AIが発見した「黄金パターン」に基づいて取引を実行
- 24/7自律稼働、週1回30分のメンテナンスのみ

### なぜ作るのか？

**主目的は学習、利益は副産物**です。

**学習目標：**
1. **AIプロンプト設計** - Claude/GeminiとのプロンプトエンジニアリングClaude/Geminiとのプロンプトエンジニアリング実践
2. **金融ニュース分析** - 市場の反応パターンを体系的に理解
3. **サーバーレス実装** - AWS Lambda/Bedrock/DynamoDBの実装経験

育児中でも継続できるよう、**自律動作設計**にこだわりました。

---

## 技術スタック

### クラウド・インフラ

- **AWS Lambda** - サーバーレス実行環境（3パターンのトリガー）
- **AWS Bedrock** - Claude 3 Haiku によるAI分析エンジン
- **DynamoDB** - ポジション管理、サーキットブレーカー
- **S3** - ニュースデータ、取引ログ保存
- **EventBridge** - イベント駆動型トリガー管理
- **Terraform** - Infrastructure as Code（IaC）

### データソース

- **Finnhub** - 米国株式ニュースAPI（無料枠）
- **Alpha Vantage** - 株価データAPI（無料枠）
- **Kaggle** - Phase 0の学習用データセット

### 開発環境

- **Python 3.11** - Lambda関数、データ分析
- **Jupyter Notebook** - Phase 0のパターン発見
- **Git/GitHub** - バージョン管理

### AI/ML

- **Claude 3 Haiku** - ニュース分析、パターン発見
- **VADER / TextBlob** - センチメント分析（補助）

---

## 4フェーズで段階的に構築

3ヶ月を4つのフェーズに分けて進めます。

### Phase 0: パターン発見（Week 1-2）

**目標**: Kaggleデータを使ってAIが「黄金パターン」を発見

- Kaggleから歴史的な株式ニュースデータを取得
- Jupyter NotebookでClaudeと対話しながら分析
- 「どんなニュースが、どんな株価変動を引き起こすか」のパターンを抽出
- 成果物: `patterns_v1.json`（5個以上のパターン）

**アプローチ**: A案（特徴量エンジニアリング）
- 人間が設計した特徴量（センチメント、騰落率等）をAIに渡す
- AIが相関パターンを発見

### Phase 1: リアルタイム自動取引システム構築（Week 3 - Month 2）

**目標**: AWSサーバーレスで24/7稼働する本番システム

**3つのトリガー**:
1. **ニュース発生時**: 5分毎にFinnhubから新規ニュース取得
2. **ボラティリティ監視**: 1分毎に株価をチェック、±2%変動で起動
3. **経済指標スケジュール**: FOMC等の重要イベント30分前/直後に起動

**サーキットブレーカー**:
- 1時間あたり最大10回トリガー
- 1日あたり最大5ポジション
- 日次損失上限: $20
- 累計損失上限: $100

**成果物**: 稼働中のAWSシステム、1週間の安定動作確認

### Phase 2: 生データ分析（Month 2後半 - Month 3前半）

**目標**: AIの創造性を引き出し、人間を超えたパターンを発見

**アプローチ**: B案（生データ分析）
- Phase 1で蓄積した生ニュース・価格データをそのままAIに渡す
- 人間が想定しない特徴をAIが自力で発見

**比較分析**:
- A案（特徴量エンジニアリング）vs B案（生データ）
- 精度、発見パターンの質、実用性を比較

**成果物**: `patterns_v2_raw.json`、比較レポート

### Phase 3: 統合と研究成果まとめ（Month 3後半）

**目標**: 知識の体系化と発信

- 3ヶ月の全取引データ分析
- A案とB案の最終評価、採用方式の決定
- 最終研究レポート作成
- GitHub公開、Qiita技術ブログ投稿

**成果物**:
- 最終研究レポート
- GitHub公開リポジトリ
- Qiita大型記事（5000字以上）

---

## 予算配分（総額5万円）

| 費目 | 金額 | 使途 |
|------|------|------|
| 証券口座証拠金 | 20,000円 | 米国株式の小ロット取引用 |
| AWS利用料 | 10,000円 | Lambda, Bedrock, S3等（3ヶ月分） |
| 予備費 | 20,000円 | 実験費用、追加コスト対応 |
| **合計** | **50,000円** | |

**ポイント**: 証拠金を抑えて予備費を厚く確保し、リスク分散。

---

## 対象銘柄

**米国テック大手5社**:
- AAPL (Apple)
- MSFT (Microsoft)
- GOOGL (Google)
- AMZN (Amazon)
- NVDA (NVIDIA)

**選定理由**:
- ニュース量が豊富（AIの学習サンプルが多い）
- 市場の注目度が高く、価格反応が明確
- 5社の比較分析で「銘柄固有」vs「市場共通」パターンを識別可能

---

## Day 1: フルセットアップ完了

昨日（2025-11-16）、プロジェクト全体のセットアップを完了しました。

**作成したもの**:
- 28個のディレクトリ
- 46個以上のファイル（Python, Terraform, Markdown）
- Lambda関数（ニュース取得、ボラティリティ監視、AI分析、取引実行）
- Terraformインフラ設定（DynamoDB, S3, Lambda, EventBridge）
- プロジェクトペルソナ4つ（Engineer, PM, PO, Blogger）

**驚いたこと**:
- Claude Codeが超強力で、フルセットアップが3時間で完了
- Makefileの網羅性（Phase 0-3すべてのコマンドが揃っている）
- サーキットブレーカーを含む実戦的なコード

**プロジェクト管理の工夫**:

複数プロジェクトで情報が錯綜しないよう、4つのペルソナを作成しました：
- **Engineer (Takeshi)**: 技術実装、コード品質
- **PM (Yuki)**: スケジュール、リソース、リスク管理
- **PO (Shinji)**: ビジョン、ユーザー価値、学習目標
- **Blogger (Syunpei)**: 学びの発信、コミュニティ貢献

AIエージェントが自律的にペルソナを選択できるルールも `.claude/CLAUDE.md` に定義しました。

---

## システムアーキテクチャ概要

```
┌─────────────────────────────────────────────────────┐
│          3つの独立したトリガーシステム                │
└─────────────────────────────────────────────────────┘
         │                │                │
         ▼                ▼                ▼
   [パターンA]      [パターンB]       [パターンC]
 ニュース発生時   ボラティリティ監視  経済指標スケジュール
         │                │                │
         └────────┬───────┴────────┬───────┘
                  ▼
           [EventBridge]
          (Custom Events)
                  │
                  ▼
          [サーキットブレーカー]
            (DynamoDB Check)
                  │
                  ▼
          [統合判断Lambda]
                  │
                  ▼
          [AI分析エンジン]
        (Bedrock Claude Haiku)
                  │
           ┌──────┴──────┐
           ▼              ▼
    [ポジション管理]   [SNS通知]
      (DynamoDB)      (Slack/LINE)
           │
           ▼
    [証券会社API]
    (取引実行)
```

**ポイント**:
- イベント駆動型で効率的なトリガー設計
- DynamoDBベースのサーキットブレーカーで暴走防止
- Bedrock (Claude Haiku)による柔軟なAI分析

---

## 育児との両立

このプロジェクトの最大の制約は「育児優先」です。

**時間確保の工夫**:
- 朝: 子供が寝ている間に30分
- 昼: 昼寝中に1-2時間（運が良ければ）
- 夜: 寝かしつけ後に1時間

→ 合計2-3時間/日が目安

**自律動作設計**:
- Phase 1以降はシステムが24/7稼働
- 週1回30分のメンテナンスのみ必須
- 日々の取引は完全自動化

**焦らない哲学**:
- Phase 0は2週間が目安だけど、毎日進めなくてもOK
- 小さな成功を祝い、楽しむことを優先
- 学びをdevlog（開発日記）に記録

---

## 次のステップ

**今週のタスク（Week 1）**:
- [x] プロジェクトセットアップ完了
- [ ] Python仮想環境構築
- [ ] Kaggle API設定
- [ ] Kaggleデータセット探索・ダウンロード
- [ ] 最初の特徴量抽出

**Phase 0の完了基準**:
- `patterns_v1.json` が生成されている
- パターン数が5個以上
- 各パターンのサンプル数が10件以上
- 分析レポートを作成

---

## まとめ

### 学んだこと

**技術面**:
- AWS Bedrockを使ったAI分析の実装パターン
- サーキットブレーカーパターンの実装方法
- Terraform modulesによる再利用可能なインフラ設計

**プロセス面**:
- Phase分割の重要性（各段階で評価しながら進める）
- ペルソナ駆動開発（複数視点で全体像を把握）
- ドキュメントファースト（設計書があるとスムーズ）

### ワクワク感

設計書を読んだ時点では「本当に作れるのか？」と不安でしたが、フルセットアップが完了して具体的なコードを見たら、一気に実感が湧きました。

Phase 0-3の全体像が見えたことで、「何をどう進めるべきか」が明確になりました。

### 次回予告

次回は**Kaggleデータ探索の冒険**です。良質なデータセットが見つかるかどうかで、Phase 0の成否が決まります。

「Financial News Headlines」「US stock earnings news」あたりで探してみます！

---

## リンク

- **GitHubリポジトリ**: [almlog/ai-trading-system](https://github.com/almlog/ai-trading-system)
- **技術スタック**: AWS Lambda, Bedrock (Claude Haiku), DynamoDB, S3, Terraform, Python 3.11

---

## タグ

`AWS` `Python` `個人開発` `育児エンジニア` `機械学習` `サーバーレス` `Terraform` `金融` `自然言語処理`

---

**シリーズ**: 「育児エンジニアの挑戦記」

**次回**: Phase 0 - Kaggleデータ探索編（予定）

---

育児の合間に学んだことを、等身大で発信します。失敗も含めて、リアルな開発記録を届けていきます！

質問・コメント・アドバイスお待ちしています 🙌
